# -*- coding: utf-8 -*-
"""Combined_Cleaning_Code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IadYibMl2kGie_PtPh2n59eYC0zNpboX

***Dice Data Architect/Scientist Code***
"""

import pandas as pd
import numpy as np

# Load the CSV file
data = pd.read_csv('dice_data_architect_scientist_with_skills.csv')

# Replace any missing values with NaN
data.fillna(value=np.nan, inplace=True)

# Remove any leading or trailing spaces in the string columns
data['title'] = data['title'].str.strip()
data['company'] = data['company'].str.strip()
data['skills'] = data['skills'].str.strip()
data['location'] = data['location'].str.strip()
data['type'] = data['type'].str.strip()

# Convert the posted_date column to datetime format
data['posted_date'] = pd.to_datetime(data['posted_date'], errors='coerce')

# Convert the salary column to numeric values, replace non-numeric values with NaN
data['salary'] = pd.to_numeric(data['salary'], errors='coerce')

# Remove any rows where salary is NaN
data = data.dropna(subset=['salary'])

# Convert hourly salaries to yearly salaries
data.loc[data['type'] == 'Hourly', 'salary'] = data['salary'] * 2080

# Print the first few rows of the cleaned data
print(data.head())

# Save the cleaned data to a new CSV file
data.to_csv('cleaned_data.csv', index=False)

"""***SQL Developer Cleaning Code***"""

import pandas as pd
from google.colab import files

# Upload the CSV file to the Google Colab environment
uploaded = files.upload()

# Read in the CSV file using Pandas
df = pd.read_csv('sql_developer_jobs.csv')

# Clean the data
df['job_title'] = df['job_title'].str.replace('-', '').str.replace('Full Time Position', '')
df['company_name'] = df['company_name'].str.replace('-', '')
df['job_description'] = df['job_description'].str.replace('\nâ€¢', '').str.replace('\n*', '')
df['salary'] = df['salary'].str.replace('Estimated: ', '')

# Remove duplicates
df = df.drop_duplicates()

# Export the cleaned data to a new CSV file
df.to_csv('cleaned_filename.csv', index=False)

# Download the cleaned CSV file to your local machine
files.download('cleaned_filename.csv')

"""***Standardizing Salary Code Along With Formatting Skills in Dice for Data Architect/Scientist***"""

import pandas as pd
from google.colab import files

def standardize_salary(salary):
    if pd.isna(salary):
        return None
    elif 'hour' in salary.lower():
        # Salary is hourly rate, convert to yearly rate
        hourly_rate = float(salary.replace('$', '').replace(',', '').replace('USD', '').split()[0])
        yearly_rate = hourly_rate * 40 * 52 # Assumes 40 hours/week and 52 weeks/year
        return yearly_rate
    else:
        # Salary is already in yearly rate
        yearly_rate_str = salary.split()[0].replace('$', '').replace(',', '').replace('USD', '')
        if yearly_rate_str.isdigit():
            yearly_rate = float(yearly_rate_str)
            return yearly_rate
        else:
            return None



# Upload the CSV file to the Google Colab environment
uploaded = files.upload()

# Read in the CSV file using Pandas
df = pd.read_csv('dice_data_architect_scientist_with_skills.csv')

# Drop rows with missing values
df = df.dropna()

# Standardize the salary column
df['yearly_rate'] = df['salary'].apply(standardize_salary)

# Split the salary column into hourly and yearly rates
salary_split = df['salary'].str.split('/', expand=True)
df['hourly_rate'] = salary_split[0].str.strip()
df['yearly_rate_from_split'] = salary_split[1].apply(standardize_salary)

# Rename the columns
df = df.rename(columns={'hourly_rate': 'hourly_rate_from_salary', 'yearly_rate_from_split': 'yearly_rate_from_salary_split'})

# Define function to handle missing and empty skills and properly format the skills
def replace_missing_skills(skills):
    if pd.isna(skills) or skills == '[]':
        return 'Unknown'
    else:
        # Remove leading/trailing white space and properly format the skills
        skills_list = [skill.strip().lower().capitalize() for skill in skills.strip('[]').split(',')]
        return ', '.join(skills_list)


# Upload the CSV file to the Google Colab environment
uploaded = files.upload()

# Read in the CSV file using Pandas
df = pd.read_csv('dice_data_architect_scientist_with_skills.csv')

# Remove rows with missing values in any column
df = df.dropna()

# Replace missing or empty skills with 'Unknown'
df['skills'] = df['skills'].apply(replace_missing_skills)

# Export the cleaned data to a new CSV file
df.to_csv('cleaned_filename.csv', index=False)

# Download the cleaned CSV file to your local machine
files.download('cleaned_filename.csv')

"""***Indeed Data Scientist Cleaning Code***"""

import pandas as pd
from google.colab import files

# Upload the CSV file to the Google Colab environment
uploaded = files.upload()

# Read in the CSV file using Pandas
df = pd.read_csv('simplyhiredjobs.csv')

# Remove rows where Job_Title is 'N'
df = df[df.Job_Title != 'N']

# Replace cells with 'N' with blank cells
df.replace('N', '', inplace=True)

# Clean the data (e.g., remove duplicates)
df = df.drop_duplicates()

# Export the cleaned data to a new CSV file
df.to_csv('cleaned_simplyhiredjobs.csv', index=False)

# Download the cleaned CSV file to your local machine
files.download('cleaned_simplyhiredjobs.csv')

"""***Cleaning Code For Dice Data Skills***"""

import pandas as pd

# Read the CSV file into a Pandas dataframe
df = pd.read_csv('cleaned_dice_data_with_skills_cleaned.csv')

# Combine the state and city into a single 'location' column
df['location'] = df['city'] + ', ' + df['state']

# Drop the original 'city' and 'state' columns
df = df.drop(['city', 'state'], axis=1)

# Remove any rows with missing values
df = df.dropna()

# Drop rows where 'Salary' is less than 40,000
df = df[df['Salary'].str.replace(',', '').str.extract(r'(\d+)', expand=False).fillna('0').astype(int) >= 40000]

# Convert 'Salary' column to 'Yearly Min' and 'Yearly Max' columns
df[['yearly min', 'yearly max']] = df['Salary'].str.replace(',', '').str.extract(r'(\d+)\D*(\d+)?', expand=True).astype(float).fillna(0)

# Drop unwanted columns
df = df.drop(columns=['Salary'])

# Save the updated DataFrame to a new CSV file
df.to_csv('jobs_updated1.csv', index=False)

"""***Code for Regex and Cleaning the Combined Indeed Files***"""

import pandas as pd

# Read the CSV file into a Pandas dataframe, specifying the encoding
df = pd.read_csv('Indeed_Job_Data_Combined.csv', encoding='utf-8')

# Replace any special characters with a '-' between texts
df = df.replace('[^a-zA-Z0-9]', '-', regex=True)

# Remove any rows with missing values
df = df.dropna()

"""***Skills Extraction Code for Indeed Jobs***"""

import pandas as pd

# Load CSV file into a DataFrame
df = pd.read_csv('Indeed_Job_Data_Combined.csv')

# Drop rows where 'Salary' is less than 40,000
df = df[df['Salary'].str.replace(',', '').str.extract(r'(\d+)', expand=False).fillna('0').astype(int) >= 40000]

# Split 'Salary' column into 'Yearly Min' and 'Yearly Max' columns
df[['Yearly Min', 'Yearly Max']] = df['Salary'].str.replace(',', '').str.extract(r'(\d+)\D*(\d+)?', expand=True).astype(float).fillna(0)

# Set 'Yearly Max' to 'Yearly Min' if it is 0
df['Yearly Max'] = df.apply(lambda row: row['Yearly Min'] if row['Yearly Max'] == 0 else row['Yearly Max'], axis=1)

# Remove the 'Salary' column
df = df.drop('Salary', axis=1)

# Format 'Yearly Min' and 'Yearly Max' columns as strings with two decimal places
df[['Yearly Min', 'Yearly Max']] = df[['Yearly Min', 'Yearly Max']].applymap('{:.2f}'.format)

# Add a 'Skills' column if one doesn't exist
if 'Skills' not in df.columns:
    df['Skills'] = ''

# Define the list of keywords
keywords = ['SQL', 'Python', 'Big Data', 'AWS', 'ETL', 'Hadoop', 'Spark', 'Kafka', 'Data Warehousing', 'Data Pipelines', 
            'Data Modeling', 'Java', 'Database Management', 'NoSQL', 'Airflow', 'Docker', 'Kubernetes', 'Redshift', 
            'Snowflake', 'Data Integration', 'Excel', 'Tableau', 'Data Visualization', 'Data Analysis', 'Dashboards', 
            'Reporting', 'Business Intelligence', 'Data Mining', 'Statistics', 'Power BI', 'Data Cleansing', 
            'Data Interpretation', 'Google Analytics', 'Data Modelling', 'Predictive Analytics', 'R$', 'Data Mapping', 
            'Machine Learning', 'Deep Learning', 'Natural Language Processing', 'Predictive Modeling', 
            'Mathematical Modeling', 'TensorFlow', 'Keras', 'Computer Vision', 'Artificial Intelligence']

# Loop over the rows in the DataFrame and update the 'Skills' column
for index, row in df.iterrows():
    job_description = row['Job Description']
    skills = []
    for keyword in keywords:
        if keyword.lower() in job_description.lower():
            if keyword.lower() == 'r$':
                if 'ruby' in job_description.lower():
                    continue
            skills.append(keyword)
    row['Skills'] = ', '.join(skills)

# Save the updated DataFrame to a new CSV file
df.to_csv('jobs_updated2.csv', index=False)